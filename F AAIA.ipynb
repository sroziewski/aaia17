{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "import pickle\n",
    "from sklearn import metrics\n",
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import (RandomTreesEmbedding, IsolationForest, RandomForestClassifier, GradientBoostingClassifier)\n",
    "\n",
    "def replaceNan(data, item):\n",
    "    return [x if x is not None else item for x in data]\n",
    "\n",
    "def getDenseFeatures(dataFrame, names, dictionary):\n",
    "    X_dense = np.empty((len(dataFrame), 0), float)\n",
    "    for name in names:\n",
    "        values = dataFrame[name].values\n",
    "        X_dense = np.column_stack([X_dense, replaceNan([dictionary[name].get(value) for value in values], 0.5)])\n",
    "    return X_dense\n",
    "def addNewFeature(data, vectors):\n",
    "    return np.column_stack([data, vectors])\n",
    "def getNewForIndexes(dataFrame, names):\n",
    "    X_selectedFeature = np.empty((len(dataFrame), 0), float)\n",
    "    for name in names:\n",
    "        X_selectedFeature = np.column_stack([X_selectedFeature, dataFrame[name].values])\n",
    "    return X_selectedFeature\n",
    "def dataScaling(data, scaler):\n",
    "    data = data/(data+1)\n",
    "    return scaler.fit_transform(data)\n",
    "\n",
    "def _computeFractionForAttribute(dataFrame, name):\n",
    "    dictionary = dict()\n",
    "    values = set(dataFrame[name].values)\n",
    "    for value in values:\n",
    "        ind = dataFrame[name].values==value\n",
    "        subset = dataFrame['decision'][ind].values\n",
    "        fraction = 1.0*len(filter(lambda x: x==1, subset)) / len(subset)\n",
    "        dictionary[value] = fraction \n",
    "    return dictionary\n",
    "def computeFractionsForAll(dataFrame, names):\n",
    "    changeDict = dict()\n",
    "    for name in names:\n",
    "        changeDict[name] = _computeFractionForAttribute(dataFrame, name)\n",
    "    return changeDict\n",
    "def dropColumnsFromDataFrame(df, columns):\n",
    "    for column in columns:\n",
    "        df = df.drop(column, 1)\n",
    "    return df\n",
    "\n",
    "def writeToFile(data, filename):\n",
    "    with open(filename, 'w') as f:\n",
    "        for item in data:\n",
    "            f.write(\"%s\\n\" % item)\n",
    "    f.close()\n",
    "def printify(t):\n",
    "    for x in t:\n",
    "        print(x)\n",
    "dataPrefix = '/home/data/aaia17/'\n",
    "def readDataAsFrame(fNames):\n",
    "    frame = []\n",
    "    for fileName in fNames:\n",
    "        fData = dataPrefix+fileName\n",
    "        frame.append(pandas.read_csv(fData))\n",
    "    return pandas.concat(frame)\n",
    "\n",
    "def read_sparse_binary_set(matrix_path):\n",
    "    return np.load(matrix_path)\n",
    "\n",
    "def dataScaling(data, scaler):\n",
    "    return scaler.fit_transform(data)\n",
    "\n",
    "trainingFiles = ['trainingData_tabular_chunk1.csv', 'trainingData_tabular_chunk2.csv',\n",
    "                 'trainingData_tabular_chunk3.csv', 'trainingData_tabular_chunk4.csv']\n",
    "rawTrainingDataset = readDataAsFrame(trainingFiles)\n",
    "testFiles = ['testData_tabular.csv']\n",
    "rawTestDataset = readDataAsFrame(testFiles)\n",
    "\n",
    "training_sparse = read_sparse_binary_set(dataPrefix + '/m.npy')\n",
    "test_sparse = read_sparse_binary_set(dataPrefix + '/m_test.npy')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make dense features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "columnsToDensify = ['opponent.hero_card_id', 'player.hero_card_id']\n",
    "chd = computeFractionsForAll(rawTrainingDataset, columnsToDensify)\n",
    "X_train_denseFeatures = getDenseFeatures(rawTrainingDataset, columnsToDensify, chd)\n",
    "X_test_denseFeatures  = getDenseFeatures(rawTestDataset, columnsToDensify, chd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Drop categorical or unnecessary features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "YRawTrainingDataset = rawTrainingDataset.values[:,1]\n",
    "columnsToDrop = ['decision','gamestate_id', 'opponent.hero_card_id', 'player.hero_card_id']\n",
    "rawDroppedTrainingDataset = dropColumnsFromDataFrame(rawTrainingDataset, columnsToDrop)\n",
    "rawDroppedTestDataset = dropColumnsFromDataFrame(rawTestDataset, columnsToDrop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add some features before scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "XRawTrainingDataset = rawDroppedTrainingDataset.values.astype(float)\n",
    "XRawTestDataset     = rawDroppedTestDataset.values.astype(float)\n",
    "\n",
    "XRawTrainingDataset = np.concatenate((XRawTrainingDataset, training_sparse[:,0:78]), axis = 1)\n",
    "XRawTestDataset = np.concatenate((XRawTestDataset, test_sparse[:,0:78]), axis = 1)\n",
    "\n",
    "assert np.all(training_sparse[:,78] == rawTrainingDataset.values[:,0]) and  np.all(test_sparse[:,78] == rawTestDataset.values[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "XTrainingDatasetScaledWithOutliers = dataScaling(XRawTrainingDataset, min_max_scaler)\n",
    "XTestDatasetScaled = dataScaling(XRawTestDataset, min_max_scaler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add new features after scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "XTrainingDatasetScaledWithOutliers = addNewFeature(XTrainingDatasetScaledWithOutliers, X_train_denseFeatures)\n",
    "XTestDatasetScaled = addNewFeature(XTestDatasetScaled, X_test_denseFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3h 39min 4s, sys: 1min 32s, total: 3h 40min 36s\n",
      "Wall time: 3h 40min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf = GradientBoostingClassifier(n_estimators=450)\n",
    "clf = clf.fit(XTrainingDatasetScaledWithOutliers, YRawTrainingDataset)\n",
    "predictedTestWon = clf.predict_proba(XTestDatasetScaled)[:,1]\n",
    "writeToFile(predictedTestWon, dataPrefix+'predicted41.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
