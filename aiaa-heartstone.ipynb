{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/opt/anaconda2/lib/python2.7/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "import pickle\n",
    "from sklearn import metrics\n",
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "def writeToFile(data, filename):\n",
    "    with open(filename, 'w') as f:\n",
    "        for item in data:\n",
    "            f.write(\"%s\\n\" % item)\n",
    "    f.close()\n",
    "def printify(t):\n",
    "    for x in t:\n",
    "        print(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data reading from all chunks and making one  dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataPrefix = '/home/data/aaia17/'\n",
    "def readDataAsFrame(fNames):\n",
    "    frame = []\n",
    "    for fileName in fNames:\n",
    "        fData = dataPrefix+fileName\n",
    "        frame.append(pandas.read_csv(fData))\n",
    "    return pandas.concat(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainingFiles = ['trainingData_tabular_chunk1.csv', 'trainingData_tabular_chunk2.csv',\n",
    "                 'trainingData_tabular_chunk3.csv', 'trainingData_tabular_chunk4.csv']\n",
    "rawTrainingDataset = readDataAsFrame(trainingFiles)\n",
    "\n",
    "testFiles = ['testData_tabular.csv']\n",
    "rawTestDataset = readDataAsFrame(testFiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decision\n",
      "0     990401\n",
      "1    1009599\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(rawTrainingDataset.groupby('decision').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decision\n",
      "0     990401\n",
      "1    1009599\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(rawTrainingDataset.groupby('decision').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000000, 45)\n",
      "(750000, 45)\n"
     ]
    }
   ],
   "source": [
    "print(rawTrainingDataset.shape)\n",
    "print(rawTestDataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(750000, 43)\n"
     ]
    }
   ],
   "source": [
    "XRawTestDataset = rawTestDataset.values[:,2:45]\n",
    "print(XRawTestDataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Outliers detection and removing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "YRawTrainingDataset = rawTrainingDataset.values[:,1]\n",
    "XRawTrainingDataset = rawTrainingDataset.values[:,2:45]\n",
    "XRawTestDataset = rawTestDataset.values[:,2:45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8min 5s, sys: 1min 4s, total: 9min 10s\n",
      "Wall time: 9min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "YRawTrainingDataset = rawTrainingDataset.values[:,1]\n",
    "XRawTrainingDataset = rawTrainingDataset.values[:,2:45]\n",
    "\n",
    "rng = np.random.RandomState(42)\n",
    "clf = IsolationForest(max_samples=10000, random_state=rng, n_jobs=-1)\n",
    "clf.fit(XRawTrainingDataset)\n",
    "\n",
    "trainingOutliers = clf.predict(XRawTrainingDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "XTrainigDatasetWithoutOutliers = XRawTrainingDataset[trainingOutliers>0]\n",
    "YTrainingDatasetWithoutOutliers = YRawTrainingDataset[trainingOutliers>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'XTrainigDatasetWithoutOutliers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-306c208295d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXTrainigDatasetWithoutOutliers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXRawTrainingDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'XTrainigDatasetWithoutOutliers' is not defined"
     ]
    }
   ],
   "source": [
    "print(XTrainigDatasetWithoutOutliers.shape)\n",
    "print(XRawTrainingDataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dataScaling(data, scaler):\n",
    "    return scaler.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "XTrainingDatasetScaledWithOutliers = dataScaling(XRawTrainingDataset, min_max_scaler)\n",
    "XTestDatasetScaled = dataScaling(XRawTestDataset, min_max_scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "XTrainingDatasetScaled = dataScaling(XTrainigDatasetWithoutOutliers, min_max_scaler)\n",
    "XTestDatasetScaled = dataScaling(XRawTestDataset, min_max_scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.0, 0.0, 1.0, 1.0)\n"
     ]
    }
   ],
   "source": [
    "print (XTrainingDatasetScaled.min(), XTestDatasetScaled.min(), \n",
    "    XTrainingDatasetScaled.max(), XTestDatasetScaled.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(750000, 43)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XTestDatasetScaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1800000, 43)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtry = XTrainingDatasetScaled\n",
    "Ytry = YTrainingDatasetWithoutOutliers\n",
    "Xtry.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 35s, sys: 14.9 s, total: 4min 50s\n",
      "Wall time: 52min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "estimator = LogisticRegression(random_state=rng)\n",
    "selector = RFECV(estimator, step=1, cv=10, scoring='roc_auc', n_jobs=-1)\n",
    "XTrainingSelected = selector.fit_transform(Xtry, Ytry)\n",
    "pickle.dump(XTrainingSelected, open(dataPrefix+'XTrainingSelected.store',\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XTrainingSelected.shape\n",
    "selector.ranking_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params_space = dict(svc__C=10.0**np.arange(-5,1),\n",
    "                    svc__kernel=['rbf', 'linear', 'poly', 'sigmoid'],\n",
    "                    svc__degree=np.arange(3,6),\n",
    "                    svc__gamma=np.logspace(-9, 3, 4),\n",
    "                    svc__probability=[True, False],\n",
    "                    svc__shrinking=[True, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid = GridSearchCV(estimator, params_space, cv=10, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating train and validation probes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "validation_size = 0.30\n",
    "seed = 7\n",
    "X_train, X_validation, Y_train, Y_validation = model_selection.train_test_split(XTrainingDatasetScaled, \n",
    "        YTrainingDatasetWithoutOutliers, test_size=validation_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validation_size = 0.30\n",
    "seed = 7\n",
    "X_train, X_validation, Y_train, Y_validation = model_selection.train_test_split(XTrainingDatasetScaledWithOutliers, \n",
    "        YRawTrainingDataset, test_size=validation_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((1260000, 43), (540000, 43), (1260000,), (540000,))\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_validation.shape, Y_train.shape, Y_validation.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test options and evaluation metric\n",
    "seed = 7\n",
    "scoring = 'roc_auc'\n",
    "models = []\n",
    "models.append(('RFC', RandomForestClassifier(n_jobs=-1, n_estimators=40)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFC: 0.862889 (0.001159)\n"
     ]
    }
   ],
   "source": [
    "# evaluate each model in turn\n",
    "%%time\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "    cv_results = model_selection.cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1440000, 43)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape\n",
    "svc_model = svm.SVC(gamma=0.001, C=100., kernel='linear')\n",
    "clf = svc_model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15h 6min 56s, sys: 2min 31s, total: 15h 9min 28s\n",
      "Wall time: 14min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf = RandomForestClassifier(n_jobs=-1, n_estimators=2000)\n",
    "clf = clf.fit(XTrainingDatasetScaledWithOutliers, YRawTrainingDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "clf = ExtraTreesClassifier(n_jobs=-1, n_estimators=1500, class_weight=\"balanced\", bootstrap=True)\n",
    "clf = clf.fit(XTrainingDatasetScaledWithOutliers, YRawTrainingDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features sorted by their score:\n",
      "(0.0646, 4)\n",
      "(0.0587, 16)\n",
      "(0.0515, 41)\n",
      "(0.0482, 42)\n",
      "(0.0452, 40)\n",
      "(0.0418, 31)\n",
      "(0.0411, 3)\n",
      "(0.0404, 34)\n",
      "(0.0377, 26)\n",
      "(0.0352, 29)\n",
      "(0.0344, 15)\n",
      "(0.0325, 33)\n",
      "(0.0323, 32)\n",
      "(0.031, 11)\n",
      "(0.03, 27)\n",
      "(0.0291, 28)\n",
      "(0.0267, 9)\n",
      "(0.026, 8)\n",
      "(0.0257, 21)\n",
      "(0.0219, 20)\n",
      "(0.0212, 39)\n",
      "(0.0197, 0)\n",
      "(0.0173, 35)\n",
      "(0.0161, 24)\n",
      "(0.0157, 36)\n",
      "(0.0152, 30)\n",
      "(0.0143, 38)\n",
      "(0.0143, 23)\n",
      "(0.0142, 12)\n",
      "(0.014, 25)\n",
      "(0.013, 7)\n",
      "(0.0117, 19)\n"
     ]
    }
   ],
   "source": [
    "print \"Features sorted by their score:\"\n",
    "names = rawTrainingDataset.columns.values[0:43]\n",
    "ranking = sorted(zip(map(lambda x: round(x, 4), clf.feature_importances_), range(0, 43)), reverse=True)\n",
    "printify(ranking[0:32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topFeatures = [x[1] for x in ranking[0:32]]\n",
    "topFeatures[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6,\n",
       " 18,\n",
       " 43,\n",
       " 44,\n",
       " 42,\n",
       " 5,\n",
       " 33,\n",
       " 28,\n",
       " 36,\n",
       " 34,\n",
       " 31,\n",
       " 17,\n",
       " 35,\n",
       " 13,\n",
       " 29,\n",
       " 30,\n",
       " 11,\n",
       " 10,\n",
       " 23,\n",
       " 22,\n",
       " 41,\n",
       " 2]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selected Feature Observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getNewForIndexes(data, indexes):\n",
    "    X_selectedFeature = np.empty((len(data), 0), float)\n",
    "    for index in indexes:\n",
    "        X_selectedFeature = np.column_stack([X_selectedFeature, data[:,index]])\n",
    "    return X_selectedFeature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_TrainSelectedFeature = getNewForIndexes(XTrainingDatasetScaledWithOutliers, topFeatures)\n",
    "X_TestSelectedFeature = getNewForIndexes(XTestDatasetScaled, topFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(750000, 32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_TestSelectedFeature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5h 17min 30s, sys: 1min 40s, total: 5h 19min 10s\n",
      "Wall time: 5min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf = RandomForestClassifier(n_jobs=-1, n_estimators=1000)\n",
    "clf = clf.fit(X_TrainSelectedFeature, YRawTrainingDataset)\n",
    "predictedTestWon = clf.predict_proba(X_TestSelectedFeature)[:,1]\n",
    "writeToFile(predictedTestWon, dataPrefix+'predicted8.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features sorted by their score:\n",
      "(0.0749, 0)\n",
      "(0.0696, 1)\n",
      "(0.0665, 2)\n",
      "(0.0605, 3)\n",
      "(0.0572, 4)\n",
      "(0.0516, 6)\n",
      "(0.0506, 5)\n",
      "(0.0488, 8)\n",
      "(0.0484, 7)\n",
      "(0.0462, 11)\n",
      "(0.0416, 10)\n",
      "(0.0404, 9)\n",
      "(0.0401, 12)\n",
      "(0.0384, 13)\n",
      "(0.0366, 14)\n",
      "(0.036, 15)\n",
      "(0.0357, 16)\n",
      "(0.0356, 18)\n",
      "(0.0334, 17)\n",
      "(0.0294, 20)\n",
      "(0.0294, 19)\n",
      "(0.0292, 21)\n"
     ]
    }
   ],
   "source": [
    "print \"Features sorted by their score:\"\n",
    "names = rawTrainingDataset.columns.values[0:43]\n",
    "ranking = sorted(zip(map(lambda x: round(x, 4), clf.feature_importances_), range(0, 22)), reverse=True)\n",
    "printify(ranking[0:22])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600000,)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.classes_\n",
    "predicted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(750000,)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictedTestWon.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-988c6535a987>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_validation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpredictedTestWon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_validation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "predicted = clf.predict(X_validation)\n",
    "predictedTestWon = predicted[:,1]\n",
    "print(metrics.classification_report(Y_validation, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictedTestWon = clf.predict_proba(XTestDatasetScaled)[:,1]\n",
    "writeToFile(predictedTestWon, dataPrefix+'predicted9.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.00000000e-09,   1.00000000e-05,   1.00000000e-01,\n",
       "         1.00000000e+03])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models.append(('KNN', KNeighborsClassifier(n_jobs=60)))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC()))\n",
    "models.append(('RF', RandomForestClassifier(n_jobs=60)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_jobs=1, n_estimators=20)\n",
    "# Utility function to report best scores\n",
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")\n",
    "            \n",
    "param_dist = {\"max_depth\": [3, None],\n",
    "              \"max_features\": sp_randint(1, 11),\n",
    "              \"min_samples_split\": sp_randint(1, 11),\n",
    "              \"min_samples_leaf\": sp_randint(1, 11),\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}     \n",
    "n_iter_search = 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1440000,)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search = RandomizedSearchCV(clf, param_distributions=param_dist, n_iter=n_iter_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'cv_results_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-cb5f9d2bb47e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m print(\"GridSearchCV took %.2f seconds for %d candidate parameter settings.\"\n\u001b[0;32m---> 19\u001b[0;31m       % (time() - start, len(grid_search.cv_results_['params'])))\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mreport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'cv_results_'"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "from sklearn.externals import joblib\n",
    "# use a full grid over all parameters\n",
    "param_grid = {\"max_depth\": [3, None],\n",
    "              \"max_features\": [5, 10, 20, 30],\n",
    "              \"min_samples_split\": [2, 3, 10],\n",
    "              \"min_samples_leaf\": [1, 3, 10],\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "# run grid search\n",
    "clf = RandomForestClassifier(n_jobs=-1, n_estimators=20)\n",
    "\n",
    "grid_search = GridSearchCV(clf, param_grid=param_grid)\n",
    "start = time()\n",
    "grid_search.fit(XTrainingDatasetScaledWithOutliers, YRawTrainingDataset)\n",
    "\n",
    "print(\"GridSearchCV took %.2f seconds for %d candidate parameter settings.\"\n",
    "      % (time() - start, len(grid_search.cv_results_['params'])))\n",
    "report(grid_search.cv_results_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': False,\n",
       " 'criterion': 'entropy',\n",
       " 'max_depth': None,\n",
       " 'max_features': 30,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_jobs=-1, n_estimators=1500, criterion=\"entropy\", bootstrap=False, max_features=30)\n",
    "clf = clf.fit(XTrainingDatasetScaledWithOutliers, YRawTrainingDataset)\n",
    "predictedTestWon = clf.predict_proba(XTestDatasetScaled)[:,1]\n",
    "writeToFile(predictedTestWon, dataPrefix+'predicted14.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=False, class_weight=None,\n",
       "            criterion='entropy', max_depth=None, max_features=30,\n",
       "            max_leaf_nodes=None, min_impurity_split=1e-07,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1500, n_jobs=-1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
